{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoUefRKcSvQK"
      },
      "outputs": [],
      "source": [
        "# Setup code for this notebook\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This is a bit of magic gto make matplotlib figures appear inline\n",
        "# in the notebook rather than in a new window\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The function is in data_utils.py file for reusing.\n",
        "import cPickle as pickle\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_CIFAR_batch(filename):\n",
        "  \"\"\" load single batch of cifar \"\"\"\n",
        "  with open(filename, 'r') as f:\n",
        "    datadict = pickle.load(f)\n",
        "    X = datadict['data']\n",
        "    Y = datadict['labels']\n",
        "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
        "    Y = np.array(Y)\n",
        "    return X, Y\n",
        "\n",
        "def load_CIFAR10(ROOT):\n",
        "  \"\"\" load all of cifar \"\"\"\n",
        "  xs = []\n",
        "  ys = []\n",
        "  for b in range(1,6):\n",
        "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
        "    X, Y = load_CIFAR_batch(f)\n",
        "    xs.append(X)\n",
        "    ys.append(Y)\n",
        "  Xtr = np.concatenate(xs)\n",
        "  Ytr = np.concatenate(ys)\n",
        "  del X, Y\n",
        "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
        "  return Xtr, Ytr, Xte, Yte"
      ],
      "metadata": {
        "id": "aj9Y7hLDS2SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from algorithms.data_utils import load_CIFAR10\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "def get_CIFAR10_data(num_training=49000, num_val=1000, num_test=10000, show_sample=True):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset, and divide the sample into training set, validation set and test set\n",
        "    \"\"\"\n",
        "\n",
        "    cifar10_dir = ''\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "\n",
        "    # subsample the data for validation set\n",
        "    mask = range(num_training, num_training + num_val)\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[list(mask)]\n",
        "    mask = range(num_training)\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = range(num_test)\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "def visualize_sample(X_train, y_train, classes, samples_per_class=7):\n",
        "    \"\"\"visualize some samples in the training datasets \"\"\"\n",
        "    num_classes = len(classes)\n",
        "    for y, cls in enumerate(classes):\n",
        "        idxs = np.flatnonzero(y_train == y) # get all the indexes of cls\n",
        "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "        for i, idx in enumerate(idxs): # plot the image one by one\n",
        "            plt_idx = i * num_classes + y + 1 # i*num_classes and y+1 determine the row and column respectively\n",
        "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "            plt.imshow(X_train[idx].astype('uint8'))\n",
        "            plt.axis('off')\n",
        "            if i == 0:\n",
        "                plt.title(cls)\n",
        "    plt.show()\n",
        "\n",
        "def preprocessing_CIFAR10_data(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "\n",
        "    # Preprocessing: reshape the image data into rows\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], -1)) # [49000, 3072]\n",
        "    X_val = np.reshape(X_val, (X_val.shape[0], -1)) # [1000, 3072]\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], -1)) # [10000, 3072]\n",
        "\n",
        "    # Normalize the data: subtract the mean image\n",
        "    mean_image = np.mean(X_train, axis = 0)\n",
        "    X_train -= mean_image\n",
        "    X_val -= mean_image\n",
        "    X_test -= mean_image\n",
        "\n",
        "    # Add bias dimension and transform into columns\n",
        "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))]).T\n",
        "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))]).T\n",
        "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))]).T\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "\n",
        "# Invoke the above functions to get our data\n",
        "X_train_raw, y_train_raw, X_val_raw, y_val_raw, X_test_raw, y_test_raw = get_CIFAR10_data()\n",
        "visualize_sample(X_train_raw, y_train_raw, classes)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = preprocessing_CIFAR10_data(X_train_raw, y_train_raw, X_val_raw, y_val_raw, X_test_raw, y_test_raw)\n",
        "\n",
        "# As a sanity check, we print out th size of the training and test data dimenstion\n",
        "print 'Train data shape: ', X_train.shape\n",
        "print 'Train labels shape: ', y_train.shape\n",
        "print 'Validation data shape: ', X_val.shape\n",
        "print 'Validation labels shape: ', y_val.shape\n",
        "print 'Test data shape: ', X_test.shape\n",
        "print 'Test labels shape: ', y_test.shape"
      ],
      "metadata": {
        "id": "3hPGcxM0S6aq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}